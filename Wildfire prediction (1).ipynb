{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53f1c167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Shreeyash Pandey\\uh\\envs\\new\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\shreeyash pandey\\uh\\envs\\new\\lib\\site-packages (0.11.2)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\shreeyash pandey\\uh\\envs\\new\\lib\\site-packages (from seaborn) (1.7.3)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\shreeyash pandey\\uh\\envs\\new\\lib\\site-packages (from seaborn) (1.4.1)\n",
      "Requirement already satisfied: matplotlib>=2.2 in c:\\users\\shreeyash pandey\\uh\\envs\\new\\lib\\site-packages (from seaborn) (3.5.1)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\shreeyash pandey\\uh\\envs\\new\\lib\\site-packages (from seaborn) (1.21.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\shreeyash pandey\\uh\\envs\\new\\lib\\site-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\shreeyash pandey\\uh\\envs\\new\\lib\\site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\shreeyash pandey\\uh\\envs\\new\\lib\\site-packages (from matplotlib>=2.2->seaborn) (9.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\shreeyash pandey\\uh\\envs\\new\\lib\\site-packages (from matplotlib>=2.2->seaborn) (1.4.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\shreeyash pandey\\uh\\envs\\new\\lib\\site-packages (from matplotlib>=2.2->seaborn) (4.31.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\shreeyash pandey\\uh\\envs\\new\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\shreeyash pandey\\uh\\envs\\new\\lib\\site-packages (from matplotlib>=2.2->seaborn) (3.0.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shreeyash pandey\\uh\\envs\\new\\lib\\site-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shreeyash pandey\\uh\\envs\\new\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras \n",
    "!pip install seaborn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7745327a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OneHotEncoder()\n",
    "encoder.fit([[0], [1]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7727a67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "paths = []\n",
    "result = []\n",
    "\n",
    "for r, d, f in os.walk(r'C:\\Users\\Shreeyash Pandey\\Downloads\\wildfire-dataset-master\\wildfire-dataset-master\\wildfire-smoke\\bing\\negative'):\n",
    "    for file in f:\n",
    "        if '.jpg' in file:\n",
    "            paths.append(os.path.join(r, file))\n",
    "\n",
    "for path in paths:\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((128,128))\n",
    "    img = np.array(img)\n",
    "    if(img.shape == (128,128,3)):\n",
    "        data.append(np.array(img))\n",
    "        result.append(encoder.transform([[0]]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92d918c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "for r, d, f in os.walk(r'C:\\Users\\Shreeyash Pandey\\Downloads\\wildfire-dataset-master\\wildfire-dataset-master\\wildfire-smoke\\bing\\positive'):\n",
    "    for file in f:\n",
    "        if '.jpg' in file:\n",
    "            paths.append(os.path.join(r, file))\n",
    "\n",
    "for path in paths:\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((128,128))\n",
    "    img = np.array(img)\n",
    "    if(img.shape == (128,128,3)):\n",
    "        data.append(np.array(img))\n",
    "        result.append(encoder.transform([[1]]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e572768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4896, 128, 128, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1595c4f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b7b518f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.array(result)\n",
    "result = result.reshape(4896,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f01eb5f",
   "metadata": {},
   "source": [
    "Spliiting the Dataset into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ea384b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(data, result, test_size=0.2, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a5205f",
   "metadata": {},
   "source": [
    "#Creating an Sequential model using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "605397ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 128, 128, 32)      416       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 64)        8256      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 64)        16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2048)              134219776 \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 135,562,178\n",
      "Trainable params: 135,561,986\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "x_train=x_train/255;\n",
    "x_test=x_test/255;\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(2, 2), input_shape=(128, 128, 3), padding = 'Same'))\n",
    "model.add(Conv2D(32, kernel_size=(2, 2),  activation ='tanh', padding = 'Same'))\n",
    "\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (2,2), activation ='relu', padding = 'Same'))\n",
    "model.add(Conv2D(64, kernel_size = (2,2), activation ='relu', padding = 'Same'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer='Adamax',metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed3f199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "284/392 [====================>.........] - ETA: 2:50 - loss: 0.4842 - accuracy: 0.8746"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs = 10, batch_size = 10, verbose = 1,validation_data =(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700afade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d94195",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
